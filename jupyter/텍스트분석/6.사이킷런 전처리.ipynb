{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea504c0e",
   "metadata": {},
   "source": [
    "### BOW (Bag Of Words)\n",
    "- 단어의 출현빈도를 수치화\n",
    "- 단어의 인덱스를 기준으로 단어(토큰)의 출현빈도를 나타낸 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3b75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DictVectorize\n",
    "# 문서에서 단어의 빈도를 딕셔너리로 입력받아 BOW 벡터를 생성해줌\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer(sparse=False)\n",
    "d = [{'java':1, 'python':2, 'mysql':3}, {'mysql':4, 'linux':5, 'html':6}]\n",
    "x = v.fit_transform(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ac4399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 3., 2.],\n",
       "       [6., 0., 5., 4., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed0ec97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html', 'java', 'linux', 'mysql', 'python']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b05fc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform({'html':5, 'oracle':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6292e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 8,\n",
       " 'is': 3,\n",
       " 'the': 6,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 5,\n",
       " 'and': 0,\n",
       " 'third': 7,\n",
       " 'last': 4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "# 문서에서 단어(토큰)을 리스트로 생성하고, 각 단어의 수를 BOW로 생성\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'this is the first document',\n",
    "    'this is the second document',\n",
    "    'and the third document',\n",
    "    'is the first document',\n",
    "    'last document'\n",
    "]\n",
    "v = CountVectorizer()\n",
    "v.fit(corpus)\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "599f7133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform(['this is the fourth document']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64989703",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this is': 9,\n",
       " 'is the': 2,\n",
       " 'the first': 5,\n",
       " 'first document': 1,\n",
       " 'the second': 6,\n",
       " 'second document': 4,\n",
       " 'and the': 0,\n",
       " 'the third': 7,\n",
       " 'third document': 8,\n",
       " 'last document': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰\n",
    "v = CountVectorizer(analyzer='word', ngram_range=(2,2)).fit(corpus)  \n",
    "# analyzer 옵션 : char, word\n",
    "# ngram_range : 단어의 순서도 고려하기 위한 옵션\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08422728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.3145539 , 0.53258605, 0.44209453, 0.        ,\n",
       "        0.        , 0.37190386, 0.        , 0.53258605],\n",
       "       [0.        , 0.29305311, 0.        , 0.41187593, 0.        ,\n",
       "        0.61500487, 0.34648301, 0.        , 0.49618205],\n",
       "       [0.62690599, 0.29872406, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3531879 , 0.62690599, 0.        ],\n",
       "       [0.        , 0.371648  , 0.62925477, 0.5223383 , 0.        ,\n",
       "        0.        , 0.43940744, 0.        , 0.        ],\n",
       "       [0.        , 0.43016528, 0.        , 0.        , 0.90275015,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TfidfVectorizer\n",
    "# Tf-idf (Term Frequency - Inverse Document Frequency)\n",
    "# 단어의 가중치를 조절해서 BOW 벡터 생성\n",
    "# 단순 단어의 개수로만 보는게 아니라, 모든 문서에 들어있는 단어의 가중치를 줄이는 방식\n",
    "# tf(단어의 빈도), idf(특정단어가 들어있는 문서의 수에 반비례 = 문서수/단어가포함된문서수)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer().fit(corpus)\n",
    "v.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5bdf28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
