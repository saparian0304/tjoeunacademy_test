{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cba1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 데이터셋 불러오기(MNIST 손글씨이미지)\n",
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95e1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.mnist\n",
    "(train_x, train_y), (test_x, test_y) = data.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5809853b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8764b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5ce509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape # 개수, 행, 열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85710edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3db0b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOE0lEQVR4nO3dcYxV5ZnH8d8jLUalENSIE9HabTDZptFBkJDYrKxNG4sm0JiuEOOw2SZDYknQNKZqRyGpGxujNGoicaqkWFmhihZs1qWGIbobk8YRWcWyrdRQHJkwokaGmEiFZ/+YQzPinPcM955zz4Xn+0km997zzLnn8To/zrn3Pee+5u4CcOo7re4GALQGYQeCIOxAEIQdCIKwA0F8qZUbMzM++gcq5u421vKm9uxmdo2Z/cnMdpvZ7c08F4BqWaPj7GY2QdKfJX1H0oCkVyUtdvc/JtZhzw5UrIo9+xxJu939HXc/LGm9pAVNPB+ACjUT9gskvTvq8UC27HPMrNvM+s2sv4ltAWhSMx/QjXWo8IXDdHfvldQrcRgP1KmZPfuApAtHPZ4uaV9z7QCoSjNhf1XSDDP7mplNlLRI0uZy2gJQtoYP4939MzNbJmmLpAmS1rj7W6V1BqBUDQ+9NbQx3rMDlavkpBoAJw/CDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Jo6ZTNOPXMmjUrWV+2bFluraurK7nuE088kaw//PDDyfr27duT9WjYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEMziiqTOzs5kva+vL1mfPHlyid183scff5ysn3POOZVtu53lzeLa1Ek1ZrZH0rCkI5I+c/fZzTwfgOqUcQbdP7v7gRKeB0CFeM8OBNFs2F3S783sNTPrHusXzKzbzPrNrL/JbQFoQrOH8Ve6+z4zO0/Si2b2f+7+8uhfcPdeSb0SH9ABdWpqz+7u+7LbIUnPSZpTRlMAytdw2M3sLDP7yrH7kr4raWdZjQEoVzOH8dMkPWdmx57nP9z9v0rpCi0zZ076YGzjxo3J+pQpU5L11Hkcw8PDyXUPHz6crBeNo8+dOze3VnSte9G2T0YNh93d35F0WYm9AKgQQ29AEIQdCIKwA0EQdiAIwg4EwSWup4Azzzwzt3b55Zcn133yySeT9enTpyfr2dBrrtTfV9Hw13333Zesr1+/PllP9dbT05Nc9957703W21neJa7s2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCKZsPgU8+uijubXFixe3sJMTU3QOwKRJk5L1l156KVmfN29ebu3SSy9NrnsqYs8OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzn4SmDVrVrJ+7bXX5taKrjcvUjSW/fzzzyfr999/f25t3759yXVff/31ZP2jjz5K1q+++urcWrOvy8mIPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBMH3xreBzs7OZL2vry9Znzx5csPbfuGFF5L1ouvhr7rqqmQ9dd34Y489llz3/fffT9aLHDlyJLf2ySefJNct+u8q+s77OjX8vfFmtsbMhsxs56hlZ5vZi2b2dnY7tcxmAZRvPIfxv5J0zXHLbpe01d1nSNqaPQbQxgrD7u4vS/rwuMULJK3N7q+VtLDctgCUrdFz46e5+6AkufugmZ2X94tm1i2pu8HtAChJ5RfCuHuvpF6JD+iAOjU69LbfzDokKbsdKq8lAFVoNOybJS3J7i+RtKmcdgBUpXCc3cyekjRP0rmS9ktaIem3kn4j6SJJeyX9wN2P/xBvrOcKeRh/ySWXJOsrVqxI1hctWpSsHzhwILc2ODiYXPeee+5J1p955plkvZ2lxtmL/u43bNiQrN94440N9dQKeePshe/Z3T3vrIpvN9URgJbidFkgCMIOBEHYgSAIOxAEYQeC4KukS3D66acn66mvU5ak+fPnJ+vDw8PJeldXV26tv78/ue4ZZ5yRrEd10UUX1d1C6dizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLOXYObMmcl60Th6kQULFiTrRdMqAxJ7diAMwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2EqxatSpZNxvzm33/rmicnHH0xpx2Wv6+7OjRoy3spD2wZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnH6frrrsut9bZ2Zlct2h64M2bNzfSEgqkxtKL/p/s2LGj5G7qV7hnN7M1ZjZkZjtHLVtpZu+Z2Y7sp7lvZwBQufEcxv9K0jVjLP+Fu3dmP/9ZblsAylYYdnd/WdKHLegFQIWa+YBumZm9kR3mT837JTPrNrN+M0tPOgagUo2GfbWkr0vqlDQo6YG8X3T3Xnef7e6zG9wWgBI0FHZ33+/uR9z9qKRfSppTblsAytZQ2M2sY9TD70vamfe7ANpD4Ti7mT0laZ6kc81sQNIKSfPMrFOSS9ojaWl1LbaH1DzmEydOTK47NDSUrG/YsKGhnk51RfPer1y5suHn7uvrS9bvuOOOhp+7XRWG3d0Xj7H48Qp6AVAhTpcFgiDsQBCEHQiCsANBEHYgCC5xbYFPP/00WR8cHGxRJ+2laGitp6cnWb/tttuS9YGBgdzaAw/knvQpSTp06FCyfjJizw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDO3gKRvyo69TXbRePkN9xwQ7K+adOmZP36669P1qNhzw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDOPk5m1lBNkhYuXJisL1++vJGW2sKtt96arN911125tSlTpiTXXbduXbLe1dWVrOPz2LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCMs4+TuzdUk6Tzzz8/WX/ooYeS9TVr1iTrH3zwQW5t7ty5yXVvuummZP2yyy5L1qdPn56s7927N7e2ZcuW5LqPPPJIso4TU7hnN7MLzWybme0ys7fMbHm2/Gwze9HM3s5up1bfLoBGjecw/jNJP3b3f5Q0V9KPzOwbkm6XtNXdZ0jamj0G0KYKw+7ug+6+Pbs/LGmXpAskLZC0Nvu1tZIWVtQjgBKc0Ht2M7tY0kxJf5A0zd0HpZF/EMzsvJx1uiV1N9kngCaNO+xmNknSRkm3uPvBoos/jnH3Xkm92XOkP8kCUJlxDb2Z2Zc1EvR17v5stni/mXVk9Q5JQ9W0CKAMhXt2G9mFPy5pl7uvGlXaLGmJpJ9nt+nv9Q1swoQJyfrNN9+crBd9JfLBgwdzazNmzEiu26xXXnklWd+2bVtu7e677y67HSSM5zD+Skk3SXrTzHZky+7USMh/Y2Y/lLRX0g8q6RBAKQrD7u7/IynvDfq3y20HQFU4XRYIgrADQRB2IAjCDgRB2IEgrOjyzFI3dhKfQZe6lPPpp59OrnvFFVc0te2isxWb+X+YujxWktavX5+sn8xfg32qcvcx/2DYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyzl6CjoyNZX7p0abLe09OTrDczzv7ggw8m1129enWyvnv37mQd7YdxdiA4wg4EQdiBIAg7EARhB4Ig7EAQhB0IgnF24BTDODsQHGEHgiDsQBCEHQiCsANBEHYgCMIOBFEYdjO70My2mdkuM3vLzJZny1ea2XtmtiP7mV99uwAaVXhSjZl1SOpw9+1m9hVJr0laKOlfJB1y9/vHvTFOqgEql3dSzXjmZx+UNJjdHzazXZIuKLc9AFU7offsZnaxpJmS/pAtWmZmb5jZGjObmrNOt5n1m1l/c60CaMa4z403s0mSXpL07+7+rJlNk3RAkkv6mUYO9f+t4Dk4jAcqlncYP66wm9mXJf1O0hZ3XzVG/WJJv3P3bxY8D2EHKtbwhTA28tWmj0vaNTro2Qd3x3xf0s5mmwRQnfF8Gv8tSf8t6U1JR7PFd0paLKlTI4fxeyQtzT7MSz0Xe3agYk0dxpeFsAPV43p2IDjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIVfOFmyA5L+OurxudmydtSuvbVrXxK9NarM3r6aV2jp9exf2LhZv7vPrq2BhHbtrV37kuitUa3qjcN4IAjCDgRRd9h7a95+Srv21q59SfTWqJb0Vut7dgCtU/eeHUCLEHYgiFrCbmbXmNmfzGy3md1eRw95zGyPmb2ZTUNd6/x02Rx6Q2a2c9Sys83sRTN7O7sdc469mnpri2m8E9OM1/ra1T39ecvfs5vZBEl/lvQdSQOSXpW02N3/2NJGcpjZHkmz3b32EzDM7J8kHZL0xLGptczsPkkfuvvPs38op7r7T9qkt5U6wWm8K+otb5rxf1WNr12Z0583oo49+xxJu939HXc/LGm9pAU19NH23P1lSR8et3iBpLXZ/bUa+WNpuZze2oK7D7r79uz+sKRj04zX+tol+mqJOsJ+gaR3Rz0eUHvN9+6Sfm9mr5lZd93NjGHasWm2stvzau7neIXTeLfScdOMt81r18j0582qI+xjTU3TTuN/V7r75ZK+J+lH2eEqxme1pK9rZA7AQUkP1NlMNs34Rkm3uPvBOnsZbYy+WvK61RH2AUkXjno8XdK+GvoYk7vvy26HJD2nkbcd7WT/sRl0s9uhmvv5O3ff7+5H3P2opF+qxtcum2Z8o6R17v5strj2126svlr1utUR9lclzTCzr5nZREmLJG2uoY8vMLOzsg9OZGZnSfqu2m8q6s2SlmT3l0jaVGMvn9Mu03jnTTOuml+72qc/d/eW/0iar5FP5P8i6ad19JDT1z9I+t/s5626e5P0lEYO6/6mkSOiH0o6R9JWSW9nt2e3UW+/1sjU3m9oJFgdNfX2LY28NXxD0o7sZ37dr12ir5a8bpwuCwTBGXRAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EMT/Az6wY9VChzNWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_x[1], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2e33fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e96b2c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a9f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "딥러닝은\n",
    "학습시 학습데이터와 검증데이터를 같이 입력\n",
    "epoch(학습횟수)마다 학습과 검증을 동시에 진행\n",
    "\n",
    "train -> train, vaild\n",
    "test\n",
    "'''\n",
    "# 검증데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d34e3ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 28, 28), (15000, 28, 28), (45000,), (15000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, valid_x.shape, train_y.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05dea44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 입력을 위해 차원 변경\n",
    "# 스케일링(색상범위값 255로 나눠줌)\n",
    "train_x = train_x.reshape(train_x.shape[0], 28*28)/255\n",
    "valid_x = valid_x.reshape(valid_x.shape[0], 28*28)/255\n",
    "test_x = test_x.reshape(test_x.shape[0], 28*28)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "081de946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label의 category값을 원핫인코딩형태로 변환\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_y = to_categorical(train_y)\n",
    "valid_y = to_categorical(valid_y)\n",
    "test_y = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e08110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "588643a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "모델 구현 방법\n",
    "1. 시퀀셜\n",
    "2. 클래스 상속\n",
    "3. 함수형\n",
    "'''\n",
    "# 시퀀셜 방식으로 구현\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9da64146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.3565 - acc: 0.8929 - val_loss: 0.1814 - val_acc: 0.9479\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.1553 - acc: 0.9542 - val_loss: 0.1621 - val_acc: 0.9517\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.1137 - acc: 0.9656 - val_loss: 0.1226 - val_acc: 0.9641\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0912 - acc: 0.9714 - val_loss: 0.1194 - val_acc: 0.9641\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0748 - acc: 0.9764 - val_loss: 0.1178 - val_acc: 0.9657\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0645 - acc: 0.9797 - val_loss: 0.1185 - val_acc: 0.9650\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0549 - acc: 0.9828 - val_loss: 0.1197 - val_acc: 0.9655\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0477 - acc: 0.9847 - val_loss: 0.1247 - val_acc: 0.9665\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0435 - acc: 0.9855 - val_loss: 0.1703 - val_acc: 0.9569\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0385 - acc: 0.9867 - val_loss: 0.1150 - val_acc: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1757dd5a9d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구현\n",
    "model = Sequential()\n",
    "# 활성화 함수(relu, sigmoid, tanh)\n",
    "model.add(Dense(64, activation='relu', input_shape=(28*28, ))) # input layer\n",
    "\n",
    "# 히든레이어 추가시(선택사항)---------\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# ------------------------------------\n",
    "\n",
    "model.add(Dense(10, activation='softmax')) # output layer\n",
    "\n",
    "# 모델 설정\n",
    "# 옵티마이저, 손실함수, 평가지표\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='acc')\n",
    "# 평가지표 - acc : 정확도(Accuracy)\n",
    "\n",
    "# 학습\n",
    "model.fit(train_x, train_y, epochs=10, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b2be3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 757us/step - loss: 0.1138 - acc: 0.9709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11383494734764099, 0.9708999991416931]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트데이터로 검증(평가)\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3568d83",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.9773 - acc: 0.7423 - val_loss: 0.3968 - val_acc: 0.9031\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.2940 - acc: 0.9247 - val_loss: 0.2441 - val_acc: 0.9332\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.2006 - acc: 0.9452 - val_loss: 0.1977 - val_acc: 0.9441\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.1569 - acc: 0.9563 - val_loss: 0.1713 - val_acc: 0.9508\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.1275 - acc: 0.9653 - val_loss: 0.1518 - val_acc: 0.9559\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.1071 - acc: 0.9708 - val_loss: 0.1421 - val_acc: 0.9591\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0908 - acc: 0.9751 - val_loss: 0.1306 - val_acc: 0.9617\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0786 - acc: 0.9774 - val_loss: 0.1226 - val_acc: 0.9655\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0677 - acc: 0.9812 - val_loss: 0.1214 - val_acc: 0.9643\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0588 - acc: 0.9834 - val_loss: 0.1242 - val_acc: 0.9637\n",
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.3526 - acc: 0.9046 - val_loss: 0.1953 - val_acc: 0.9418\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.1543 - acc: 0.9540 - val_loss: 0.1416 - val_acc: 0.9562\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.1075 - acc: 0.9682 - val_loss: 0.1288 - val_acc: 0.9618\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0838 - acc: 0.9747 - val_loss: 0.1107 - val_acc: 0.9667\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0670 - acc: 0.9796 - val_loss: 0.1088 - val_acc: 0.9675\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0560 - acc: 0.9828 - val_loss: 0.1178 - val_acc: 0.9659\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0454 - acc: 0.9862 - val_loss: 0.1282 - val_acc: 0.9637\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0390 - acc: 0.9881 - val_loss: 0.1191 - val_acc: 0.9655\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0348 - acc: 0.9890 - val_loss: 0.1185 - val_acc: 0.9684\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0274 - acc: 0.9914 - val_loss: 0.1265 - val_acc: 0.9656\n",
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.3381 - acc: 0.9011 - val_loss: 0.1834 - val_acc: 0.9461\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.1528 - acc: 0.9547 - val_loss: 0.1411 - val_acc: 0.9590\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.1102 - acc: 0.9658 - val_loss: 0.1333 - val_acc: 0.9608\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0882 - acc: 0.9726 - val_loss: 0.1264 - val_acc: 0.9637\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0724 - acc: 0.9777 - val_loss: 0.1241 - val_acc: 0.9651\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0598 - acc: 0.9812 - val_loss: 0.1338 - val_acc: 0.9615\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0522 - acc: 0.9827 - val_loss: 0.1240 - val_acc: 0.9666\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0447 - acc: 0.9855 - val_loss: 0.1203 - val_acc: 0.9665\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0391 - acc: 0.9871 - val_loss: 0.1241 - val_acc: 0.9692\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 0.0358 - acc: 0.9879 - val_loss: 0.1342 - val_acc: 0.9681\n"
     ]
    }
   ],
   "source": [
    "# 활성화 함수 비교\n",
    "for f in ['sigmoid', 'tanh', 'relu'] :\n",
    "    # 모델 구현\n",
    "    model = Sequential()\n",
    "    # 활성화 함수(relu, sigmoid, tanh)\n",
    "    model.add(Dense(64, activation=f, input_shape=(28*28, ))) # input layer\n",
    "\n",
    "    # 히든레이어 추가시(선택사항)---------\n",
    "    model.add(Dense(32, activation=f))\n",
    "    model.add(Dense(32, activation=f))\n",
    "    # ------------------------------------\n",
    "\n",
    "    model.add(Dense(10, activation='softmax')) # output layer\n",
    "\n",
    "    # 모델 설정\n",
    "    # 옵티마이저, 손실함수, 평가지표\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='acc')\n",
    "    # 평가지표 - acc : 정확도(Accuracy)\n",
    "\n",
    "    # 학습\n",
    "    model.fit(train_x, train_y, epochs=10, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc2d26b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.2693075 , 0.3289329 , 0.40175956], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax함수\n",
    "tf.nn.softmax([0.1, 0.3, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ac5bdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax([0.1, 0.3, 0.5]).numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a10b617f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 1ms/step - loss: 0.3822 - acc: 0.8880 - val_loss: 0.2015 - val_acc: 0.9415\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1646 - acc: 0.9518 - val_loss: 0.1497 - val_acc: 0.9546\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1178 - acc: 0.9641 - val_loss: 0.1217 - val_acc: 0.9627\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0918 - acc: 0.9729 - val_loss: 0.1176 - val_acc: 0.9649\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0763 - acc: 0.9759 - val_loss: 0.1242 - val_acc: 0.9647\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0637 - acc: 0.9799 - val_loss: 0.1147 - val_acc: 0.9677\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0524 - acc: 0.9832 - val_loss: 0.1103 - val_acc: 0.9688\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0499 - acc: 0.9840 - val_loss: 0.1067 - val_acc: 0.9718\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0409 - acc: 0.9872 - val_loss: 0.1112 - val_acc: 0.9700\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0354 - acc: 0.9883 - val_loss: 0.1140 - val_acc: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x175051251c0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 설정\n",
    "# optimizer\n",
    "# SGD : 확률적 경사 하강법, 랜덤데이터의 가중치를 사용, 정확도 떨어짐\n",
    "# RMSprop : 학습률을 조정해서 속도 개선(Adagrad 개선)\n",
    "# Adam : RMSprop랑 Adagrad가 결합된 버전 (현재까지는 가장 좋은 성능)\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# 손실함수\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# 모델 구현\n",
    "model = Sequential()\n",
    "# 활성화 함수(relu, sigmoid, tanh)\n",
    "model.add(Dense(64, activation='relu', input_shape=(28*28, ))) # input layer\n",
    "\n",
    "# 히든레이어 추가시(선택사항)---------\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# ------------------------------------\n",
    "\n",
    "model.add(Dense(10, activation='softmax')) # output layer\n",
    "\n",
    "# 모델 설정\n",
    "# 옵티마이저, 손실함수, 평가지표\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=CategoricalCrossentropy(), metrics='acc')\n",
    "# 평가지표 - acc : 정확도(Accuracy)\n",
    "\n",
    "# 학습\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=50,validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2fc573d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "900/900 [==============================] - 2s 1ms/step - loss: 0.3736 - acc: 0.8890 - val_loss: 0.2008 - val_acc: 0.9403\n",
      "Epoch 2/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1565 - acc: 0.9533 - val_loss: 0.1539 - val_acc: 0.9546\n",
      "Epoch 3/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1163 - acc: 0.9650 - val_loss: 0.1523 - val_acc: 0.9548\n",
      "Epoch 4/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0961 - acc: 0.9705 - val_loss: 0.1229 - val_acc: 0.9638\n",
      "Epoch 5/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0778 - acc: 0.9763 - val_loss: 0.1243 - val_acc: 0.9642\n",
      "Epoch 6/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0673 - acc: 0.9790 - val_loss: 0.1158 - val_acc: 0.9683\n",
      "Epoch 7/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0555 - acc: 0.9818 - val_loss: 0.1108 - val_acc: 0.9699\n",
      "Epoch 8/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0477 - acc: 0.9848 - val_loss: 0.1183 - val_acc: 0.9681\n",
      "Epoch 9/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0427 - acc: 0.9860 - val_loss: 0.1242 - val_acc: 0.9678\n",
      "Epoch 10/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0366 - acc: 0.9883 - val_loss: 0.1287 - val_acc: 0.9678\n",
      "Epoch 11/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0328 - acc: 0.9892 - val_loss: 0.1286 - val_acc: 0.9695\n",
      "Epoch 12/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0298 - acc: 0.9904 - val_loss: 0.1490 - val_acc: 0.9641\n",
      "Epoch 13/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0262 - acc: 0.9912 - val_loss: 0.1333 - val_acc: 0.9692\n",
      "Epoch 14/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0232 - acc: 0.9923 - val_loss: 0.1436 - val_acc: 0.9672\n",
      "Epoch 15/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0221 - acc: 0.9924 - val_loss: 0.1550 - val_acc: 0.9669\n",
      "Epoch 16/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0196 - acc: 0.9930 - val_loss: 0.1628 - val_acc: 0.9641\n",
      "Epoch 17/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0188 - acc: 0.9935 - val_loss: 0.1687 - val_acc: 0.9663\n",
      "Epoch 18/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0164 - acc: 0.9945 - val_loss: 0.1698 - val_acc: 0.9676\n",
      "Epoch 19/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.1646 - val_acc: 0.9671\n",
      "Epoch 20/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.1726 - val_acc: 0.9653\n",
      "Epoch 21/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.1861 - val_acc: 0.9664\n",
      "Epoch 22/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9961 - val_loss: 0.1816 - val_acc: 0.9685\n",
      "Epoch 23/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0144 - acc: 0.9947 - val_loss: 0.1940 - val_acc: 0.9654\n",
      "Epoch 24/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0169 - acc: 0.9944 - val_loss: 0.1941 - val_acc: 0.9662\n",
      "Epoch 25/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.1897 - val_acc: 0.9672\n",
      "Epoch 26/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.2021 - val_acc: 0.9688\n",
      "Epoch 27/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.9958 - val_loss: 0.2006 - val_acc: 0.9676\n",
      "Epoch 28/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.1947 - val_acc: 0.9693\n",
      "Epoch 29/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.9970 - val_loss: 0.2345 - val_acc: 0.9647\n",
      "Epoch 30/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.2138 - val_acc: 0.9669\n",
      "Epoch 31/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.1998 - val_acc: 0.9711\n",
      "Epoch 32/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.1998 - val_acc: 0.9696\n",
      "Epoch 33/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.2252 - val_acc: 0.9673\n",
      "Epoch 34/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.2093 - val_acc: 0.9681\n",
      "Epoch 35/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.2256 - val_acc: 0.9691\n",
      "Epoch 36/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 0.9953 - val_loss: 0.2249 - val_acc: 0.9688\n",
      "Epoch 37/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.2244 - val_acc: 0.9682\n",
      "Epoch 38/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.9967 - val_loss: 0.2254 - val_acc: 0.9684\n",
      "Epoch 39/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.2055 - val_acc: 0.9719\n",
      "Epoch 40/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.9971 - val_loss: 0.2469 - val_acc: 0.9668\n",
      "Epoch 41/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.9961 - val_loss: 0.2248 - val_acc: 0.9685\n",
      "Epoch 42/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0090 - acc: 0.9973 - val_loss: 0.2345 - val_acc: 0.9671\n",
      "Epoch 43/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.2485 - val_acc: 0.9673\n",
      "Epoch 44/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.2420 - val_acc: 0.9708\n",
      "Epoch 45/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.2252 - val_acc: 0.9701\n",
      "Epoch 46/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.2324 - val_acc: 0.9711\n",
      "Epoch 47/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.9959 - val_loss: 0.2505 - val_acc: 0.9685\n",
      "Epoch 48/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.2421 - val_acc: 0.9679\n",
      "Epoch 49/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.9971 - val_loss: 0.2484 - val_acc: 0.9693\n",
      "Epoch 50/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.2257 - val_acc: 0.9715\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "\n",
    "# 모델 구현\n",
    "model = Sequential()\n",
    "# 활성화 함수(relu, sigmoid, tanh)\n",
    "model.add(Dense(64, activation='relu', input_shape=(28*28, ))) # input layer\n",
    "\n",
    "# 히든레이어 추가시(선택사항)---------\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# ------------------------------------\n",
    "\n",
    "model.add(Dense(10, activation='softmax')) # output layer\n",
    "\n",
    "# 모델 설정\n",
    "# 옵티마이저, 손실함수, 평가지표\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='acc')\n",
    "# 평가지표 - acc : 정확도(Accuracy)\n",
    "\n",
    "# 학습\n",
    "history = model.fit(train_x, train_y, epochs=50, batch_size=50,validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e51b653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3736475706100464,\n",
       "  0.15650276839733124,\n",
       "  0.11633538454771042,\n",
       "  0.0960909053683281,\n",
       "  0.07780486345291138,\n",
       "  0.06734658032655716,\n",
       "  0.05549219995737076,\n",
       "  0.047694530338048935,\n",
       "  0.04271969571709633,\n",
       "  0.0366467647254467,\n",
       "  0.032793108373880386,\n",
       "  0.02976861223578453,\n",
       "  0.026158971711993217,\n",
       "  0.023196915164589882,\n",
       "  0.02205898053944111,\n",
       "  0.019642150029540062,\n",
       "  0.018793581053614616,\n",
       "  0.016398996114730835,\n",
       "  0.017849262803792953,\n",
       "  0.018484193831682205,\n",
       "  0.013664702884852886,\n",
       "  0.01115345023572445,\n",
       "  0.014389383606612682,\n",
       "  0.01685505546629429,\n",
       "  0.009593089111149311,\n",
       "  0.015542054548859596,\n",
       "  0.012245915830135345,\n",
       "  0.012946846894919872,\n",
       "  0.009159239009022713,\n",
       "  0.013915483839809895,\n",
       "  0.008214781992137432,\n",
       "  0.011553766205906868,\n",
       "  0.010366811417043209,\n",
       "  0.008253238163888454,\n",
       "  0.010759302414953709,\n",
       "  0.014135949313640594,\n",
       "  0.004799296613782644,\n",
       "  0.010142759419977665,\n",
       "  0.006952133495360613,\n",
       "  0.009426116943359375,\n",
       "  0.01236541848629713,\n",
       "  0.00904250331223011,\n",
       "  0.008474729023873806,\n",
       "  0.009569542482495308,\n",
       "  0.006475561298429966,\n",
       "  0.005133769474923611,\n",
       "  0.013295033015310764,\n",
       "  0.006623076740652323,\n",
       "  0.00840977393090725,\n",
       "  0.00998692400753498],\n",
       " 'acc': [0.8889999985694885,\n",
       "  0.95333331823349,\n",
       "  0.9649778008460999,\n",
       "  0.970466673374176,\n",
       "  0.9763110876083374,\n",
       "  0.979022204875946,\n",
       "  0.9818221926689148,\n",
       "  0.984844446182251,\n",
       "  0.9860000014305115,\n",
       "  0.9883333444595337,\n",
       "  0.9891777634620667,\n",
       "  0.990422248840332,\n",
       "  0.9911777973175049,\n",
       "  0.9922666549682617,\n",
       "  0.992377758026123,\n",
       "  0.9929999709129333,\n",
       "  0.9935333132743835,\n",
       "  0.994533360004425,\n",
       "  0.9941999912261963,\n",
       "  0.9940000176429749,\n",
       "  0.9956666827201843,\n",
       "  0.996066689491272,\n",
       "  0.9947111010551453,\n",
       "  0.9943777918815613,\n",
       "  0.9968222379684448,\n",
       "  0.9951555728912354,\n",
       "  0.9958222508430481,\n",
       "  0.9958222508430481,\n",
       "  0.9969555735588074,\n",
       "  0.995555579662323,\n",
       "  0.9973777532577515,\n",
       "  0.996066689491272,\n",
       "  0.9964666962623596,\n",
       "  0.9974666833877563,\n",
       "  0.996577799320221,\n",
       "  0.9953110814094543,\n",
       "  0.9985555410385132,\n",
       "  0.9967111349105835,\n",
       "  0.997866690158844,\n",
       "  0.9971333146095276,\n",
       "  0.9960888624191284,\n",
       "  0.9973111152648926,\n",
       "  0.9971555471420288,\n",
       "  0.9967555403709412,\n",
       "  0.997688889503479,\n",
       "  0.9983111023902893,\n",
       "  0.9958666563034058,\n",
       "  0.9978222250938416,\n",
       "  0.9971110820770264,\n",
       "  0.9969111084938049],\n",
       " 'val_loss': [0.20079006254673004,\n",
       "  0.1539091318845749,\n",
       "  0.15232379734516144,\n",
       "  0.12285226583480835,\n",
       "  0.12430976331233978,\n",
       "  0.11580988019704819,\n",
       "  0.11077549308538437,\n",
       "  0.1182781457901001,\n",
       "  0.12418024241924286,\n",
       "  0.1287175714969635,\n",
       "  0.12855489552021027,\n",
       "  0.14904646575450897,\n",
       "  0.13332068920135498,\n",
       "  0.1435735672712326,\n",
       "  0.15495377779006958,\n",
       "  0.1628393828868866,\n",
       "  0.168743297457695,\n",
       "  0.1698344200849533,\n",
       "  0.16463275253772736,\n",
       "  0.17261512577533722,\n",
       "  0.1860923022031784,\n",
       "  0.18164603412151337,\n",
       "  0.19402046501636505,\n",
       "  0.19410468637943268,\n",
       "  0.18974173069000244,\n",
       "  0.20207533240318298,\n",
       "  0.20058085024356842,\n",
       "  0.19470737874507904,\n",
       "  0.23454652726650238,\n",
       "  0.2138022780418396,\n",
       "  0.19980138540267944,\n",
       "  0.19982360303401947,\n",
       "  0.22515881061553955,\n",
       "  0.2093309611082077,\n",
       "  0.22560124099254608,\n",
       "  0.22491666674613953,\n",
       "  0.2244301438331604,\n",
       "  0.22541409730911255,\n",
       "  0.2055104672908783,\n",
       "  0.24691709876060486,\n",
       "  0.22475561499595642,\n",
       "  0.2344721257686615,\n",
       "  0.24847780168056488,\n",
       "  0.24201397597789764,\n",
       "  0.22518710792064667,\n",
       "  0.23238694667816162,\n",
       "  0.25052186846733093,\n",
       "  0.24205072224140167,\n",
       "  0.24839064478874207,\n",
       "  0.22572357952594757],\n",
       " 'val_acc': [0.9402666687965393,\n",
       "  0.9545999765396118,\n",
       "  0.954800009727478,\n",
       "  0.9638000130653381,\n",
       "  0.9642000198364258,\n",
       "  0.9682666659355164,\n",
       "  0.9698666930198669,\n",
       "  0.9680666923522949,\n",
       "  0.9678000211715698,\n",
       "  0.9678000211715698,\n",
       "  0.9694666862487793,\n",
       "  0.9640666842460632,\n",
       "  0.9692000150680542,\n",
       "  0.967199981212616,\n",
       "  0.9669333100318909,\n",
       "  0.9640666842460632,\n",
       "  0.9662666916847229,\n",
       "  0.9675999879837036,\n",
       "  0.9671333432197571,\n",
       "  0.9653333425521851,\n",
       "  0.9664000272750854,\n",
       "  0.9685333371162415,\n",
       "  0.965399980545044,\n",
       "  0.9661999940872192,\n",
       "  0.967199981212616,\n",
       "  0.9688000082969666,\n",
       "  0.9675999879837036,\n",
       "  0.9693333506584167,\n",
       "  0.9646666646003723,\n",
       "  0.9669333100318909,\n",
       "  0.9711333513259888,\n",
       "  0.9696000218391418,\n",
       "  0.9672666788101196,\n",
       "  0.9680666923522949,\n",
       "  0.9690666794776917,\n",
       "  0.9688000082969666,\n",
       "  0.9682000279426575,\n",
       "  0.9684000015258789,\n",
       "  0.9719333052635193,\n",
       "  0.9667999744415283,\n",
       "  0.9685333371162415,\n",
       "  0.9670666456222534,\n",
       "  0.9673333168029785,\n",
       "  0.97079998254776,\n",
       "  0.9701333045959473,\n",
       "  0.9710666537284851,\n",
       "  0.9685333371162415,\n",
       "  0.9678666591644287,\n",
       "  0.9693333506584167,\n",
       "  0.9714666604995728]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b2dd2f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss(학습데이터의 로스)와 val_loss(검증데이터의 로스) 비교\n",
    "plt.plot(history.history['loss'], c='r')\n",
    "plt.plot(history.history['val_loss'], c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1c3b0858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 789us/step - loss: 0.2232 - acc: 0.9707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22315539419651031, 0.9707000255584717]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33d09578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 644us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 968,    0,    2,    2,    0,    1,    2,    2,    3,    0],\n",
       "       [   0, 1124,    1,    2,    0,    1,    1,    1,    5,    0],\n",
       "       [   2,    1, 1007,   10,    1,    0,    1,    4,    5,    1],\n",
       "       [   0,    0,    9,  986,    0,    2,    0,    4,    7,    2],\n",
       "       [   4,    0,    5,    0,  936,    3,    7,    2,    1,   24],\n",
       "       [   2,    1,    0,   18,    1,  854,    8,    1,    5,    2],\n",
       "       [  11,    3,    2,    1,    5,    5,  928,    0,    3,    0],\n",
       "       [   1,    2,   11,    2,    4,    1,    0,  992,    4,   11],\n",
       "       [   3,    0,    8,    8,    3,    1,    5,    6,  935,    5],\n",
       "       [   2,    3,    1,   11,    8,    4,    0,    3,    0,  977]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 혼동행렬(confusion matrix)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(test_x)\n",
    "confusion_matrix(np.argmax(test_y, axis=1), np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "352cadc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3006688e-14, 1.6864660e-13, 5.7207791e-17, 9.7595404e-12,\n",
       "       1.0986964e-21, 9.9569936e-14, 2.7116116e-30, 9.9999976e-01,\n",
       "       7.0303979e-14, 2.6590533e-07], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84cbcf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4e5d55ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8f17f4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.96      0.98      0.97      1032\n",
      "           3       0.95      0.98      0.96      1010\n",
      "           4       0.98      0.95      0.96       982\n",
      "           5       0.98      0.96      0.97       892\n",
      "           6       0.97      0.97      0.97       958\n",
      "           7       0.98      0.96      0.97      1028\n",
      "           8       0.97      0.96      0.96       974\n",
      "           9       0.96      0.97      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류보고서\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(test_y, axis=1), np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cbcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
