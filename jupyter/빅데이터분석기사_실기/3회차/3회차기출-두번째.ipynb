{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275f23d5",
   "metadata": {},
   "source": [
    "# 작업형 1유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58215f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. 다음은 California Housing 데이터 세트이다. 데이터 중 결측치가 있는 경우 해당 데이터의 행을 모두 제거하고, 첫번째 행부터 순서대로 70%까지의 데이터를 훈련 데이터로 추출한 데이터 세트를 구성한다. 변수 중 ‘housing_median_age’의 Q1(제1사분위수)값을 정수로 계산하시오.\n",
    "301_housing.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0106e4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('301_housing.csv')\n",
    "# print(data.info())\n",
    "data1 = data[~data['total_bedrooms'].isnull()]\n",
    "# print(len(data1)*0.7)\n",
    "num = int(len(data1)*0.7)\n",
    "print(int(data1.iloc[:num]['housing_median_age'].quantile(0.25)))\n",
    "# print(data1.quantile(0.25))\n",
    "# print(data1.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. 다음은 국가별 연도별 인구 10만명당 결핵 유병률 데이터세트이다. 2000년도의 국가별 결핵 유병률 데이터 세트에서 2000년도의 평균값보다 더 큰 유병률 값을 가진 국가의 수를 계산하시오.\n",
    "302_worlddata.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bec48c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albania                 132.0\n",
      "Andorra                 138.0\n",
      "Antigua & Barbuda       128.0\n",
      "Armenia                 179.0\n",
      "Bahamas                 176.0\n",
      "                        ...  \n",
      "United Arab Emirates    135.0\n",
      "United Kingdom          126.0\n",
      "USA                     158.0\n",
      "Uzbekistan              101.0\n",
      "Venezuela               100.0\n",
      "Name: 2000, Length: 76, dtype: float64\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('302_worlddata.csv')\n",
    "# print(help(pd.DataFrame.transpose))\n",
    "data = data.set_index('year')\n",
    "data1 = data.T\n",
    "data2 = data1.loc[:, 2000]\n",
    "print(data2[data2 > data2.mean()])\n",
    "# data1 = data.loc[data.loc[:,] == 2002].T\n",
    "\n",
    "print(int(len(data2[data2 > data2.mean()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f25f2d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('302_worlddata.csv')\n",
    "# print(data.head())\n",
    "data1 = data[data['year']==2000].T\n",
    "data1 = data1.drop('year')\n",
    "# print(data1, data1.drop('year'))\n",
    "print(len(data1[data1[1] > data1[1].mean()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93052780",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. 다음은 Titanic 데이터 세트이다. 주어진 데이터 세트의 컬럼 중 빈 값 또는 결측치를 확인하여, 결측치의 비율이 가장 높은 변수명을 출력하시오.\n",
    "303_titanic.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d31db715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('303_titanic.csv')\n",
    "# print(data.info())\n",
    "print(data.isnull().sum().sort_values(ascending=False).index[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a77e38e",
   "metadata": {},
   "source": [
    "# 작업형 2유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b4185",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "다음은 Travel Insuarance 데이터 세트이다. 주어진 훈련 데이터 세트를 이용하여 고객별 여행보험 가입 여부 예측모형을 만들고, 가장 높은 Accuracy값을 가지는 최종모델을 도출하시오. 해당 모델을 활용하여 보험가입여부 예측값을 계산하고 결과값은 csv파일로 제출하시오.\n",
    "304_x_test.csv\n",
    "304_x_train.csv\n",
    "304_y_train.csv\n",
    "* 결과 제출 양식 : ID, TravelInsurance\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6b2776bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "       ID  TravelInsurance\n",
      "0    1569                0\n",
      "1    1344                1\n",
      "2    1429                0\n",
      "3     896                0\n",
      "4     101                1\n",
      "..    ...              ...\n",
      "492  1376                0\n",
      "493    87                0\n",
      "494   287                0\n",
      "495   337                0\n",
      "496    92                0\n",
      "\n",
      "[497 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import pandas as pd \n",
    "x_train = pd.read_csv('304_x_train.csv')\n",
    "y_train = pd.read_csv('304_y_train.csv')\n",
    "x_test = pd.read_csv('304_x_test.csv')\n",
    "# print(x_train.shape, y_train.shape, x_test.shape)\n",
    "\n",
    "# 데이터 살펴보기\n",
    "# print(x_train.info())\n",
    "# print(x_train.head())\n",
    "\n",
    "# 범주형 데이터 보기\n",
    "# print(x_train['Employment Type'].value_counts())\n",
    "# print(x_test['Employment Type'].value_counts())\n",
    "\n",
    "# print(x_train['GraduateOrNot'].value_counts())\n",
    "# print(x_test['GraduateOrNot'].value_counts())\n",
    "\n",
    "# print(x_train['FrequentFlyer'].value_counts())\n",
    "# print(x_test['FrequentFlyer'].value_counts())\n",
    "\n",
    "# print(x_train['EverTravelledAbroad'].value_counts())\n",
    "# print(x_test['EverTravelledAbroad'].value_counts())\n",
    "\n",
    "# 데이터 이상값, 결측치 처리\n",
    "# 데이터 라벨링\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "x_train['Employment Type'] = encoder.fit_transform(x_train['Employment Type'])\n",
    "x_test['Employment Type'] = encoder.transform(x_test['Employment Type'])\n",
    "# print(x_train['Employment Type'].value_counts())\n",
    "# print(x_test['Employment Type'].value_counts())\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "x_train['GraduateOrNot'] = encoder.fit_transform(x_train['GraduateOrNot'])\n",
    "x_test['GraduateOrNot'] = encoder.transform(x_test['GraduateOrNot'])\n",
    "# print(x_train['GraduateOrNot'].value_counts())\n",
    "# print(x_test['GraduateOrNot'].value_counts())\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "x_train['FrequentFlyer'] = encoder.fit_transform(x_train['FrequentFlyer'])\n",
    "x_test['FrequentFlyer'] = encoder.transform(x_test['FrequentFlyer'])\n",
    "# print(x_train['FrequentFlyer'].value_counts())\n",
    "# print(x_test['FrequentFlyer'].value_counts())\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "x_train['EverTravelledAbroad'] = encoder.fit_transform(x_train['EverTravelledAbroad'])\n",
    "x_test['EverTravelledAbroad'] = encoder.transform(x_test['EverTravelledAbroad'])\n",
    "# print(x_train['EverTravelledAbroad'].value_counts())\n",
    "# print(x_test['EverTravelledAbroad'].value_counts())\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "x_train['Employment Type'] = encoder.fit_transform(x_train['Employment Type'])\n",
    "x_test['Employment Type'] = encoder.transform(x_test['Employment Type'])\n",
    "# print(x_train['Employment Type'].value_counts())\n",
    "# print(x_test['Employment Type'].value_counts())\n",
    "# 스케일링 - 나이, 수입\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x_train['Age'] = scaler.fit_transform(x_train[['Age']])\n",
    "x_test['Age'] = scaler.transform(x_test[['Age']])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train['AnnualIncome'] = scaler.fit_transform(x_train[['AnnualIncome']])\n",
    "x_test['AnnualIncome'] = scaler.transform(x_test[['AnnualIncome']])\n",
    "# print(x_train.describe())\n",
    "\n",
    "# 데이터 분리(split)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_TRAIN, X_VALID, Y_TRAIN, Y_VALID = train_test_split(x_train.drop(columns='ID'), y_train.drop(columns='ID'))\n",
    "# print(X_TRAIN.shape, X_VALID.shape, Y_TRAIN.shape, Y_VALID.shape)\n",
    "# 모델 학습 및 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(n_estimators=500, max_depth=5)\n",
    "model.fit(X_TRAIN, Y_TRAIN)\n",
    "Y_TEST_PREDICTED = model.predict(X_VALID)\n",
    "# print(accuracy_score(Y_VALID, Y_TEST_PREDICTED))\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth=5)\n",
    "model.fit(X_TRAIN, Y_TRAIN)\n",
    "Y_TEST_PREDICTED = model.predict(X_VALID)\n",
    "# print(accuracy_score(Y_VALID, Y_TEST_PREDICTED))\n",
    "# 모델 재학습\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth=5)\n",
    "model.fit(x_train.drop(columns='ID'), y_train.drop(columns='ID'))\n",
    "y_test_predicted = pd.DataFrame(model.predict(x_test.drop(columns='ID')))\n",
    "\n",
    "# 결과 제출\n",
    "result = pd.concat([x_test['ID'], y_test_predicted], axis=1)\n",
    "result.columns = ['ID', 'TravelInsurance']\n",
    "result.to_csv('12345.csv', index=False)\n",
    "print(pd.read_csv('12345.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ad385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408841aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
